{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\shrad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\shrad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\shrad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\shrad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\shrad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 29 tokens\n",
      "\n",
      "{'Gensim': 0, 'Python': 1, 'a': 2, 'algorithms.': 3, 'and': 4, 'as': 5, 'designed': 6, 'digital': 7, 'documents': 8, 'efficiently': 9, 'for': 10, 'free': 11, 'is': 12, 'learning': 13, 'library': 14, 'machine': 15, 'open-source': 16, 'painlessly': 17, 'possible.': 18, 'process': 19, 'raw,': 20, 'representing': 21, 'semantic': 22, 'texts': 23, 'to': 24, 'unstructured': 25, 'unsupervised': 26, 'using': 27, 'vectors,': 28}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "text1 = [\"\"\"Gensim is a free open-source Python library for representing documents as semantic vectors,\n",
    "           as efficiently and painlessly as possible. Gensim is designed \n",
    "           to process raw, unstructured digital texts using unsupervised machine learning algorithms.\"\"\"]\n",
    "\n",
    "tokens1 = [[item for item in line.split()] for line in text1]\n",
    "g_dict1 = corpora.Dictionary(tokens1)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict1)) + \" tokens\\n\")\n",
    "print(g_dict1.token2id)\n",
    "#Each token in the dictionary is assigned with unique id............"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words :  [[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#Bag of words.........\n",
    "#The Bag of Words returns a vector of tuples containing each token’s unique id \n",
    "#and the number of occurrences in the document.\n",
    "g_bow =[g_dict1.doc2bow(token, allow_update = True) for token in tokens1]\n",
    "print(\"Bag of Words : \", g_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary : \n",
      "[['be', 1], ['better', 1], ['but', 1], ['can', 1], ['excellent', 1], ['food', 1], ['is', 1], ['service', 1], ['the', 2]]\n",
      "[['food', 1], ['is', 1], ['service', 1], ['the', 2], ['always', 1], ['and', 1], ['delicious', 1], ['loved', 1]]\n",
      "[['food', 1], ['service', 1], ['the', 2], ['and', 1], ['mediocre', 1], ['terrible', 1], ['was', 2]]\n",
      "TF-IDF Vector:\n",
      "[['be', 0.43], ['better', 0.43], ['but', 0.43], ['can', 0.43], ['excellent', 0.43], ['food', 0.09], ['is', 0.21], ['service', 0.09], ['the', 0.18]]\n",
      "[['food', 0.11], ['is', 0.26], ['service', 0.11], ['the', 0.21], ['always', 0.52], ['and', 0.26], ['delicious', 0.52], ['loved', 0.52]]\n",
      "[['food', 0.08], ['service', 0.08], ['the', 0.16], ['and', 0.2], ['mediocre', 0.39], ['terrible', 0.39], ['was', 0.78]]\n"
     ]
    }
   ],
   "source": [
    "#Creating TF-IDF................\n",
    "#Term Frequency – Inverse Document Frequency” (TF-IDF) \n",
    "#is a technique for measuring the importance of each word in a document by computing the word’s weight.\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import models\n",
    "import numpy as np\n",
    "text = [\"The food is excellent but the service can be better\",\n",
    "        \"The food is always delicious and loved the service\",\n",
    "        \"The food was mediocre and the service was terrible\"]\n",
    "\n",
    "g_dict = corpora.Dictionary([simple_preprocess(line) for line in text])\n",
    "g_bow = [g_dict.doc2bow(simple_preprocess(line)) for line in text]\n",
    "\n",
    "print(\"Dictionary : \")\n",
    "for item in g_bow:\n",
    "    print([[g_dict[id], freq] for id, freq in item])\n",
    "\n",
    "g_tfidf = models.TfidfModel(g_bow, smartirs='ntc')\n",
    "\n",
    "print(\"TF-IDF Vector:\")\n",
    "for item in g_tfidf[g_bow]:\n",
    "    print([[g_dict[id], np.around(freq, decimals=2)] for id, freq in item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n",
      "[('political', 0.8020443916320801), ('cultural', 0.7465336918830872), ('norms', 0.722484290599823), ('intellectual', 0.7092244625091553), ('attitudes', 0.708358883857727), ('ideology', 0.7055392265319824), ('economic', 0.6993893384933472), ('welfare', 0.6983789801597595), ('progressive', 0.697333812713623), ('libertarian', 0.6909048557281494)]\n"
     ]
    }
   ],
   "source": [
    "#Creating a Word2Vec model..................\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "import gensim.downloader as api\n",
    "\n",
    "dataset = api.load(\"text8\")\n",
    "words = [d for d in dataset]\n",
    "\n",
    "data1 = words[:1000]\n",
    "w2v_model = Word2Vec(data1, min_count = 0, workers=cpu_count())\n",
    "print(w2v_model.wv.most_similar('social'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
